from lxml import etree
import requests
from bs4 import BeautifulSoup
import html5lib
from pyecharts import Bar
import re
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36',
    
}
# url="https://www.gushiwen.org/default.aspx?page=1"
# url="https://www.gushiwen.org/default.aspx?page=1"
urls=[]
# urls.append(url)
data=[]
# https://www.gushiwen.org/default_2.aspx
# https://www.gushiwen.org/default_3.aspx
def parse_page(url):
    resp = requests.get(url,headers=HEADERS)
    html = resp.content.decode('utf-8')
#   print(html)
    titles=re.findall(r'<div class="cont">.*?<b>(.*?)</b>',html,re.DOTALL)
#     print(titles)
    chaodais=re.findall('<p class="source"><a.*?>(.*?)</a>',html)
#     print(chaodais)
    authors=re.findall('<p class="source">.*?</span><a.*?>(.*?)</a>',html)
#     print(authors)
    contents=re.findall('<div class="contson" .*?>(.*?)</div>',html,re.DOTALL)
#     print(contents)
    piems=[]
    for content in contents:
        eachcontent= re.sub(r"<.*?>","",content)
        piems.append(eachcontent.strip())
#         print(eachcontent.strip())      
        
    
    for value in zip(titles,chaodais,authors,piems):
        title,chaodai,author,piem=value
        temp={
            "title":title,
            "chaodai":chaodai,
            "author":author,
            "piem":piem
        }
        data.append(temp)
#     print(data)
    return data

def alldata():
    for i in range(1,5):
        url="https://www.gushiwen.org/default_{}.aspx".format(i)
        urls.append(url)
    for url in urls:
        parse_page(url)

if __name__ == '__main__':
    alldata()
    print(urls)
    print(data)
    print("exit0")
